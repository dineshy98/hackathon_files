{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_main = pd.read_csv('S:/Hackathons/TCS/train_main.csv')\n",
    "train_main.drop(columns = ['proj_id','cand_id'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_same_loc</th>\n",
       "      <th>mode</th>\n",
       "      <th>numb_comm_skills</th>\n",
       "      <th>top_score</th>\n",
       "      <th>eulc_dist</th>\n",
       "      <th>jacard_score_b/w_skills</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.072502</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>SELECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.111115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SELECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SELECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.084265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SELECTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.105762</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>REJECTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_same_loc  mode  numb_comm_skills  top_score  eulc_dist  \\\n",
       "0            1     0                 1        0.2   0.072502   \n",
       "1            0     0                 0        0.2   0.111115   \n",
       "2            1     0                 0        0.1   0.067958   \n",
       "3            1     0                 0        0.2   0.084265   \n",
       "4            1     0                 1        0.4   0.105762   \n",
       "\n",
       "   jacard_score_b/w_skills    result  \n",
       "0                 0.166667  SELECTED  \n",
       "1                 0.000000  SELECTED  \n",
       "2                 0.000000  SELECTED  \n",
       "3                 0.000000  SELECTED  \n",
       "4                 0.200000  REJECTED  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr,X_tst,y_tr,y_tst = train_test_split(train_main.drop(columns = ['result']),train_main['result'],\n",
    "                                         stratify = train_main['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-7727a48eee29>:15: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  score_card = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "params_xg = {\n",
    "        'n_estimators': [750,1000,1250,1500,2000],\n",
    "        'max_depth':[7,15,20],\n",
    "        'min_child_weight': [3, 10],\n",
    "        'gamma': [0.5,2, 5],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.7, 1.0]\n",
    "        }\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,log_loss,accuracy_score\n",
    "score_card = pd.Series()\n",
    "\n",
    "def best_grid_model(estimator,X_tr,X_tst,y_tr,y_tst,parmas_grid):\n",
    "    \n",
    "    grid = GridSearchCV(estimator=estimator,\n",
    "                    param_grid=parmas_grid,\n",
    "                    cv=3,  \n",
    "                    verbose=10, \n",
    "                    n_jobs=-1,\n",
    "                    scoring='accuracy',\n",
    "                    refit = True)\n",
    "    \n",
    "    grid.fit(X_tr,y_tr)\n",
    "    print('Best Parmaters are :',grid.best_params_)\n",
    "    print('ReFitting Best Parameters to New Estimator ...............','\\n')\n",
    "    print('Best Score is :',grid.best_score_)\n",
    "    best_estimator = estimator\n",
    "    best_estimator.set_params(**grid.best_params_)\n",
    "    best_estimator.fit(X_tr,y_tr)\n",
    "    \n",
    "    \n",
    "    best_accuracy_score = accuracy_score(y_tst,best_estimator.predict(X_tst))\n",
    "    print('RMSE for X_test is :',best_accuracy_score,'\\n' )\n",
    "    \n",
    "    score_card['best_{}'.format(estimator)] = best_accuracy_score\n",
    "    \n",
    "    return grid,best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  7.0min finished\n",
      "C:\\Users\\dines\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Parmaters are : {'colsample_bytree': 0.7, 'gamma': 5, 'max_depth': 7, 'min_child_weight': 10, 'n_estimators': 1000, 'subsample': 0.8}\n",
      "ReFitting Best Parameters to New Estimator ............... \n",
      "\n",
      "Best Score is : 0.5765379113018598\n",
      "[03:30:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "RMSE for X_test is : 0.5579399141630901 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_xgb,best_xgb = best_grid_model(xgboost.XGBClassifier(),X_tr,X_tst,y_tr,y_tst,params_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56963426, 0.43036574],\n",
       "       [0.42179763, 0.57820237],\n",
       "       [0.5355673 , 0.46443272],\n",
       "       ...,\n",
       "       [0.44053555, 0.55946445],\n",
       "       [0.5949291 , 0.40507087],\n",
       "       [0.5182581 , 0.48174194]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_main = pd.read_csv('S:/Hackathons/TCS/test_main.csv')\n",
    "best_xgb.predict_proba(test_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['REJECTED', 'SELECTED'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(best_xgb.predict_proba(test_main),columns = best_xgb.classes_)\n",
    "preds.to_csv('S:/Hackathons/TCS/preds1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
